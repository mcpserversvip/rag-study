"""
åŒ»ç–—å®‰å…¨æ£€æŸ¥æ¨¡å—
åŒ…å«ç”¨è¯å®‰å…¨ã€ä¼¦ç†æ£€æŸ¥ã€äººæ–‡å…³æ€€ç­‰åŠŸèƒ½
"""
from typing import Dict, List, Optional
import re

from src.utils.logger import logger
from src.config import settings


class SafetyChecker:
    """åŒ»ç–—å®‰å…¨æ£€æŸ¥å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®‰å…¨æ£€æŸ¥å™¨"""
        self.enable_safety_check = settings.enable_safety_check
        self.enable_ethics_check = settings.enable_ethics_check
        self.enable_humanistic_care = settings.enable_humanistic_care
        
        # é«˜é£é™©å…³é”®è¯
        self.high_risk_keywords = [
            "ç«‹å³", "ç´§æ€¥", "å±é™©", "ä¸¥é‡", "è‡´å‘½",
            "åœè¯", "åŠ é‡", "å‡é‡", "æ¢è¯",
            "æ‰‹æœ¯", "ä½é™¢", "æ€¥è¯Š"
        ]
        
        # ç¦å¿Œè¯
        self.forbidden_keywords = [
            "ä¿è¯æ²»æ„ˆ", "å®Œå…¨æ²»æ„ˆ", "æ ¹æ²»",
            "ç»å¯¹å®‰å…¨", "æ²¡æœ‰å‰¯ä½œç”¨",
            "æœ€å¥½çš„è¯", "å”¯ä¸€çš„é€‰æ‹©"
        ]
        
        # éœ€è¦äººæ–‡å…³æ€€çš„æƒ…å†µ
        self.care_keywords = [
            "æ‹…å¿ƒ", "å®³æ€•", "ç„¦è™‘", "ç´§å¼ ",
            "ç—›è‹¦", "éš¾å—", "ä¸èˆ’æœ",
            "å¹¶å‘ç—‡", "æ¶åŒ–", "ä¸¥é‡"
        ]
    
    def check_medication_safety(self, medication_info: Dict) -> Dict[str, any]:
        """
        æ£€æŸ¥ç”¨è¯å®‰å…¨
        
        Args:
            medication_info: ç”¨è¯ä¿¡æ¯å­—å…¸
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        if not self.enable_safety_check:
            return {"safe": True, "warnings": []}
        
        logger.info("æ‰§è¡Œç”¨è¯å®‰å…¨æ£€æŸ¥")
        
        warnings = []
        
        # æ£€æŸ¥å‰‚é‡æ˜¯å¦åˆç†(ç¤ºä¾‹)
        if "dosage" in medication_info:
            dosage = medication_info["dosage"]
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„å‰‚é‡æ£€æŸ¥é€»è¾‘
            logger.debug(f"æ£€æŸ¥å‰‚é‡: {dosage}")
        
        # æ£€æŸ¥è¯ç‰©ç›¸äº’ä½œç”¨(ç¤ºä¾‹)
        if "current_medications" in medication_info and "new_medication" in medication_info:
            # è¿™é‡Œå¯ä»¥æ·»åŠ è¯ç‰©ç›¸äº’ä½œç”¨æ£€æŸ¥é€»è¾‘
            logger.debug("æ£€æŸ¥è¯ç‰©ç›¸äº’ä½œç”¨")
        
        # æ£€æŸ¥ç¦å¿Œç—‡(ç¤ºä¾‹)
        if "contraindications" in medication_info:
            contraindications = medication_info["contraindications"]
            if contraindications:
                warnings.append(f"æ³¨æ„ç¦å¿Œç—‡: {contraindications}")
        
        return {
            "safe": len(warnings) == 0,
            "warnings": warnings
        }
    
    def check_content_ethics(self, content: str) -> Dict[str, any]:
        """
        æ£€æŸ¥å†…å®¹ä¼¦ç†
        
        Args:
            content: å¾…æ£€æŸ¥å†…å®¹
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        if not self.enable_ethics_check:
            return {"passed": True, "issues": []}
        
        logger.info("æ‰§è¡Œä¼¦ç†æ£€æŸ¥")
        
        issues = []
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¦å¿Œè¯
        for keyword in self.forbidden_keywords:
            if keyword in content:
                issues.append(f"åŒ…å«ä¸å½“æ‰¿è¯º: '{keyword}'")
                logger.warning(f"å‘ç°ç¦å¿Œè¯: {keyword}")
        
        # æ£€æŸ¥æ˜¯å¦è¿‡åº¦æ‰¿è¯ºç–—æ•ˆ
        if re.search(r'(100%|ç™¾åˆ†ä¹‹ç™¾|ä¸€å®š|å¿…ç„¶).*?(æ²»æ„ˆ|åº·å¤|ç—Šæ„ˆ)', content):
            issues.append("å­˜åœ¨è¿‡åº¦æ‰¿è¯ºç–—æ•ˆçš„è¡¨è¿°")
        
        # æ£€æŸ¥æ˜¯å¦å°Šé‡æ‚£è€…è‡ªä¸»æƒ
        if "å¿…é¡»" in content and "å»ºè®®" not in content:
            issues.append("è¡¨è¿°è¿‡äºå¼ºåˆ¶,å»ºè®®ä½¿ç”¨'å»ºè®®'ç­‰è¯æ±‡")
        
        return {
            "passed": len(issues) == 0,
            "issues": issues
        }
    
    def detect_high_risk_content(self, content: str) -> Dict[str, any]:
        """
        æ£€æµ‹é«˜é£é™©å†…å®¹
        
        Args:
            content: å¾…æ£€æµ‹å†…å®¹
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        logger.info("æ£€æµ‹é«˜é£é™©å†…å®¹")
        
        high_risk_items = []
        
        for keyword in self.high_risk_keywords:
            if keyword in content:
                high_risk_items.append(keyword)
        
        is_high_risk = len(high_risk_items) > 0
        
        if is_high_risk:
            logger.warning(f"æ£€æµ‹åˆ°é«˜é£é™©å†…å®¹,å…³é”®è¯: {high_risk_items}")
        
        return {
            "is_high_risk": is_high_risk,
            "risk_keywords": high_risk_items,
            "warning_message": "âš ï¸ æœ¬å»ºè®®æ¶‰åŠé‡è¦åŒ»ç–—å†³ç­–,è¯·åŠ¡å¿…å’¨è¯¢ä¸»æ²»åŒ»ç”Ÿåå†æ‰§è¡Œã€‚" if is_high_risk else ""
        }
    
    def add_humanistic_care(self, content: str, patient_context: Optional[str] = None) -> str:
        """
        æ·»åŠ äººæ–‡å…³æ€€å†…å®¹
        
        Args:
            content: åŸå§‹å†…å®¹
            patient_context: æ‚£è€…ä¸Šä¸‹æ–‡(å¯é€‰)
            
        Returns:
            æ·»åŠ äººæ–‡å…³æ€€åçš„å†…å®¹
        """
        if not self.enable_humanistic_care:
            return content
        
        logger.info("æ·»åŠ äººæ–‡å…³æ€€å†…å®¹")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹åˆ«å…³æ€€
        needs_care = False
        if patient_context:
            for keyword in self.care_keywords:
                if keyword in patient_context:
                    needs_care = True
                    break
        
        # æ·»åŠ äººæ–‡å…³æ€€å‰ç¼€
        care_prefix = ""
        if needs_care:
            care_prefix = "ğŸ’™ æˆ‘ç†è§£æ‚¨çš„æ‹…å¿§å’Œä¸å®‰ã€‚è¯·æ”¾å¿ƒ,æˆ‘ä»¬ä¼šä¸€èµ·é¢å¯¹è¿™ä¸ªé—®é¢˜ã€‚\n\n"
        
        # æ·»åŠ äººæ–‡å…³æ€€åç¼€
        care_suffix = "\n\nğŸ’™ æ¸©é¦¨æç¤º:\n"
        care_suffix += "- æ…¢æ€§ç—…ç®¡ç†æ˜¯ä¸€ä¸ªé•¿æœŸè¿‡ç¨‹,è¯·ä¿æŒè€å¿ƒå’Œä¿¡å¿ƒ\n"
        care_suffix += "- è§„å¾‹æœè¯ã€å¥åº·ç”Ÿæ´»æ–¹å¼æ˜¯æ§åˆ¶ç–¾ç—…çš„å…³é”®\n"
        care_suffix += "- å¦‚æœ‰ä»»ä½•ä¸é€‚æˆ–ç–‘é—®,è¯·åŠæ—¶å’¨è¯¢æ‚¨çš„ä¸»æ²»åŒ»ç”Ÿ\n"
        care_suffix += "- ä¿æŒç§¯æä¹è§‚çš„å¿ƒæ€,å¯¹ç–¾ç—…æ§åˆ¶å¾ˆæœ‰å¸®åŠ©\n"
        
        return care_prefix + content + care_suffix
    
    def add_disclaimer(self, content: str) -> str:
        """
        æ·»åŠ å…è´£å£°æ˜
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            æ·»åŠ å…è´£å£°æ˜åçš„å†…å®¹
        """
        disclaimer = "\n\n" + "="*80 + "\n"
        disclaimer += "âš ï¸ ã€é‡è¦å£°æ˜ã€‘\n"
        disclaimer += "æœ¬å»ºè®®ä»…ä¾›åŒ»ç–—ä¸“ä¸šäººå‘˜å‚è€ƒ,ä¸èƒ½æ›¿ä»£åŒ»ç”Ÿçš„ä¸´åºŠåˆ¤æ–­ã€‚\n"
        disclaimer += "æ‰€æœ‰è¯Šç–—å†³ç­–è¯·åœ¨åŒ»ç”ŸæŒ‡å¯¼ä¸‹è¿›è¡Œã€‚\n"
        disclaimer += "å¦‚æœ‰ç´§æ€¥æƒ…å†µ,è¯·ç«‹å³å°±åŒ»æˆ–æ‹¨æ‰“120æ€¥æ•‘ç”µè¯ã€‚\n"
        disclaimer += "="*80
        
        return content + disclaimer
    
    def comprehensive_check(
        self, 
        content: str, 
        patient_context: Optional[str] = None,
        medication_info: Optional[Dict] = None
    ) -> Dict[str, any]:
        """
        ç»¼åˆå®‰å…¨æ£€æŸ¥
        
        Args:
            content: å¾…æ£€æŸ¥å†…å®¹
            patient_context: æ‚£è€…ä¸Šä¸‹æ–‡
            medication_info: ç”¨è¯ä¿¡æ¯
            
        Returns:
            ç»¼åˆæ£€æŸ¥ç»“æœ
        """
        logger.info("æ‰§è¡Œç»¼åˆå®‰å…¨æ£€æŸ¥")
        
        results = {
            "original_content": content,
            "processed_content": content,
            "checks": {}
        }
        
        # 1. ä¼¦ç†æ£€æŸ¥
        ethics_result = self.check_content_ethics(content)
        results["checks"]["ethics"] = ethics_result
        
        if not ethics_result["passed"]:
            logger.warning(f"ä¼¦ç†æ£€æŸ¥æœªé€šè¿‡: {ethics_result['issues']}")
        
        # 2. é«˜é£é™©æ£€æµ‹
        risk_result = self.detect_high_risk_content(content)
        results["checks"]["risk"] = risk_result
        
        # 3. ç”¨è¯å®‰å…¨æ£€æŸ¥
        if medication_info:
            med_safety_result = self.check_medication_safety(medication_info)
            results["checks"]["medication_safety"] = med_safety_result
        
        # 4. æ·»åŠ äººæ–‡å…³æ€€
        processed_content = self.add_humanistic_care(content, patient_context)
        
        # 5. æ·»åŠ é«˜é£é™©è­¦å‘Š
        if risk_result["is_high_risk"]:
            processed_content = risk_result["warning_message"] + "\n\n" + processed_content
        
        # 6. æ·»åŠ å…è´£å£°æ˜
        processed_content = self.add_disclaimer(processed_content)
        
        results["processed_content"] = processed_content
        results["safe_to_display"] = ethics_result["passed"]
        
        return results


# å…¨å±€å®‰å…¨æ£€æŸ¥å™¨å®ä¾‹
safety_checker = SafetyChecker()


def get_safety_checker() -> SafetyChecker:
    """è·å–å®‰å…¨æ£€æŸ¥å™¨å®ä¾‹"""
    return safety_checker


if __name__ == "__main__":
    # æµ‹è¯•å®‰å…¨æ£€æŸ¥
    checker = get_safety_checker()
    
    # æµ‹è¯•å†…å®¹
    test_content = "å»ºè®®æ‚¨ç«‹å³åœè¯,æ”¹ç”¨æ–°çš„é™ç³–è¯ç‰©ã€‚è¿™ä¸ªæ–¹æ¡ˆä¿è¯æ²»æ„ˆæ‚¨çš„ç³–å°¿ç—…ã€‚"
    test_context = "æ‚£è€…è¡¨ç¤ºå¾ˆæ‹…å¿ƒå¹¶å‘ç—‡"
    
    logger.info("æµ‹è¯•å®‰å…¨æ£€æŸ¥")
    
    result = checker.comprehensive_check(
        content=test_content,
        patient_context=test_context
    )
    
    print("\n" + "="*80)
    print("åŸå§‹å†…å®¹:")
    print(result["original_content"])
    print("\n" + "="*80)
    print("æ£€æŸ¥ç»“æœ:")
    print(f"ä¼¦ç†æ£€æŸ¥: {'é€šè¿‡' if result['checks']['ethics']['passed'] else 'æœªé€šè¿‡'}")
    if not result['checks']['ethics']['passed']:
        print(f"  é—®é¢˜: {result['checks']['ethics']['issues']}")
    print(f"é«˜é£é™©æ£€æµ‹: {'æ˜¯' if result['checks']['risk']['is_high_risk'] else 'å¦'}")
    if result['checks']['risk']['is_high_risk']:
        print(f"  é£é™©å…³é”®è¯: {result['checks']['risk']['risk_keywords']}")
    print("\n" + "="*80)
    print("å¤„ç†åå†…å®¹:")
    print(result["processed_content"])
    print("="*80)

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ é…ç½®çš„ API Key æ˜¯ï¼šsk-4b*****\n"
     ]
    }
   ],
   "source": [
    "from config.load_key import load_key\n",
    "import os\n",
    "\n",
    "load_key()\n",
    "# ç”Ÿäº§ç¯å¢ƒä¸­è¯·å‹¿å°† API Key è¾“å‡ºåˆ°æ—¥å¿—ä¸­ï¼Œé¿å…æ³„éœ²\n",
    "print(f'''ä½ é…ç½®çš„ API Key æ˜¯ï¼š{os.environ[\"DASHSCOPE_API_KEY\"][:5]+\"*\"*5}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åœ¨docsæ–‡ä»¶å¤¹ä¸­å‡†å¤‡äº†ä¸€äº›è™šæ„çš„å…¬å¸åˆ¶åº¦æ–‡ä»¶ï¼Œæ¥ä¸‹æ¥ä½ å°†åŸºäºè¿™äº›æ–‡ä»¶æ¥åˆ›å»ºRAGåº”ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è§£ææ–‡ä»¶...\n",
      "æ­£åœ¨åˆ›å»ºç´¢å¼•...\n",
      "æ­£åœ¨åˆ›å»ºæé—®å¼•æ“...\n",
      "æ­£åœ¨ç”Ÿæˆå›å¤...\n",
      "å›ç­”æ˜¯ï¼š\n",
      "æ— æ³•æä¾›ç›¸å…³ä¿¡æ¯ã€‚"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ä¾èµ–\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding,DashScopeTextEmbeddingModels\n",
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "# è¿™ä¸¤è¡Œä»£ç æ˜¯ç”¨äºæ¶ˆé™¤ WARNING è­¦å‘Šä¿¡æ¯ï¼Œé¿å…å¹²æ‰°é˜…è¯»å­¦ä¹ ï¼Œç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®æ ¹æ®éœ€è¦æ¥è®¾ç½®æ—¥å¿—çº§åˆ«\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"æ­£åœ¨è§£ææ–‡ä»¶...\")\n",
    "# LlamaIndexæä¾›äº†SimpleDirectoryReaderæ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å°†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶åŠ è½½ä¸ºdocumentå¯¹è±¡ï¼Œå¯¹åº”ç€è§£æè¿‡ç¨‹\n",
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "\n",
    "print(\"æ­£åœ¨åˆ›å»ºç´¢å¼•...\")\n",
    "# from_documentsæ–¹æ³•åŒ…å«åˆ‡ç‰‡ä¸å»ºç«‹ç´¢å¼•æ­¥éª¤\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    # æŒ‡å®šembedding æ¨¡å‹\n",
    "    embed_model=DashScopeEmbedding(\n",
    "        # ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘æä¾›çš„å…¶å®ƒembeddingæ¨¡å‹ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models#3383780daf8hw\n",
    "        model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V3,\n",
    "        embed_input_length=8192,\n",
    "        embed_batch_size=6,\n",
    "        )\n",
    ")\n",
    "print(\"æ­£åœ¨åˆ›å»ºæé—®å¼•æ“...\")\n",
    "query_engine = index.as_query_engine(\n",
    "    # è®¾ç½®ä¸ºæµå¼è¾“å‡º\n",
    "    streaming=True,\n",
    "    # æ­¤å¤„ä½¿ç”¨qwen-plus-0919æ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘æä¾›çš„å…¶å®ƒqwençš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
    "    llm=OpenAILike(\n",
    "        model=\"qwen-plus-2025-09-11\",\n",
    "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        is_chat_model=True\n",
    "        ))\n",
    "print(\"æ­£åœ¨ç”Ÿæˆå›å¤...\")\n",
    "streaming_response = query_engine.query('æŸ¥çœ‹è™šæ‹Ÿç¯å¢ƒå‘½ä»¤æ˜¯ä»€ä¹ˆï¼Ÿ')\n",
    "print(\"å›ç­”æ˜¯ï¼š\")\n",
    "# é‡‡ç”¨æµå¼è¾“å‡º\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ä¿å­˜ä¸åŠ è½½ç´¢å¼•\n",
    "ä½ å¯èƒ½ä¼šå‘ç°ï¼Œåˆ›å»ºç´¢å¼•æ¶ˆè€—çš„æ—¶é—´æ¯”è¾ƒé•¿ã€‚å¦‚æœèƒ½å¤Ÿå°†ç´¢å¼•ä¿å­˜åˆ°æœ¬åœ°ï¼Œå¹¶åœ¨éœ€è¦ä½¿ç”¨çš„æ—¶å€™ç›´æ¥åŠ è½½ï¼Œè€Œä¸æ˜¯é‡æ–°å»ºç«‹ç´¢å¼•ï¼Œé‚£å°±å¯ä»¥å¤§å¹…æå‡å›å¤çš„é€Ÿåº¦ï¼ŒLlamaIndexæä¾›äº†ç®€å•æ˜“å®ç°çš„ä¿å­˜ä¸åŠ è½½ç´¢å¼•çš„æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç´¢å¼•æ–‡ä»¶ä¿å­˜åˆ°äº†knowledge_base/test\n"
     ]
    }
   ],
   "source": [
    "# å°†ç´¢å¼•ä¿å­˜ä¸ºæœ¬åœ°æ–‡ä»¶\n",
    "index.storage_context.persist(\"knowledge_base/test\")\n",
    "print(\"ç´¢å¼•æ–‡ä»¶ä¿å­˜åˆ°äº†knowledge_base/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆåŠŸä»knowledge_base/testè·¯å¾„åŠ è½½ç´¢å¼•\n"
     ]
    }
   ],
   "source": [
    "# å°†æœ¬åœ°ç´¢å¼•æ–‡ä»¶åŠ è½½ä¸ºç´¢å¼•\n",
    "from llama_index.core import StorageContext,load_index_from_storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"knowledge_base/test\")\n",
    "index = load_index_from_storage(storage_context,embed_model=DashScopeEmbedding(\n",
    "        model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V2\n",
    "    ))\n",
    "print(\"æˆåŠŸä»knowledge_base/testè·¯å¾„åŠ è½½ç´¢å¼•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»æœ¬åœ°åŠ è½½ç´¢å¼•åï¼Œä½ å¯ä»¥å†æ¬¡è¿›è¡Œæé—®æµ‹è¯•æ˜¯å¦å¯ä»¥æ­£å¸¸å·¥ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åˆ›å»ºæé—®å¼•æ“...\n",
      "æ­£åœ¨ç”Ÿæˆå›å¤...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1536,) and (1024,) not aligned: 1536 (dim 0) != 1024 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      2\u001b[39m query_engine = index.as_query_engine(\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# è®¾ç½®ä¸ºæµå¼è¾“å‡º\u001b[39;00m\n\u001b[32m      4\u001b[39m     streaming=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m         is_chat_model=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     11\u001b[39m         ))\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mæ­£åœ¨ç”Ÿæˆå›å¤...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m streaming_response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43må†…éƒ¨æ§åˆ¶è¯„ä»·ç»“è®ºï¼Ÿ\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33må›ç­”æ˜¯ï¼š\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m streaming_response.print_response_stream()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     51\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m dispatcher.event(\n\u001b[32m     54\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     55\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:189\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    187\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    188\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._response_synthesizer.synthesize(\n\u001b[32m    191\u001b[39m         query=query_bundle,\n\u001b[32m    192\u001b[39m         nodes=nodes,\n\u001b[32m    193\u001b[39m     )\n\u001b[32m    194\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:144\u001b[39m, in \u001b[36mRetrieverQueryEngine.retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_node_postprocessors(nodes, query_bundle=query_bundle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/base/base_retriever.py:243\u001b[39m, in \u001b[36mBaseRetriever.retrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    240\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    241\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    242\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m         nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m         nodes = \u001b[38;5;28mself\u001b[39m._handle_recursive_retrieval(query_bundle, nodes)\n\u001b[32m    245\u001b[39m         retrieve_event.on_end(\n\u001b[32m    246\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    247\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    253\u001b[39m     id_=id_,\n\u001b[32m    254\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     tags=tags,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:101\u001b[39m, in \u001b[36mVectorIndexRetriever._retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle.embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle.embedding_strs) > \u001b[32m0\u001b[39m:\n\u001b[32m     96\u001b[39m         query_bundle.embedding = (\n\u001b[32m     97\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_model.get_agg_embedding_from_queries(\n\u001b[32m     98\u001b[39m                 query_bundle.embedding_strs\n\u001b[32m     99\u001b[39m             )\n\u001b[32m    100\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:177\u001b[39m, in \u001b[36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[39m\u001b[34m(self, query_bundle_with_embeddings)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_nodes_with_embeddings\u001b[39m(\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[32m    175\u001b[39m ) -> List[NodeWithScore]:\n\u001b[32m    176\u001b[39m     query = \u001b[38;5;28mself\u001b[39m._build_vector_store_query(query_bundle_with_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_node_list_from_query_result(query_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/vector_stores/simple.py:376\u001b[39m, in \u001b[36mSimpleVectorStore.query\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     top_similarities, top_ids = get_top_k_mmr_embeddings(\n\u001b[32m    369\u001b[39m         query_embedding,\n\u001b[32m    370\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m         mmr_threshold=mmr_threshold,\n\u001b[32m    374\u001b[39m     )\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query.mode == VectorStoreQueryMode.DEFAULT:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     top_similarities, top_ids = \u001b[43mget_top_k_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid query mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery.mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/indices/query/embedding_utils.py:30\u001b[39m, in \u001b[36mget_top_k_embeddings\u001b[39m\u001b[34m(query_embedding, embeddings, similarity_fn, similarity_top_k, embedding_ids, similarity_cutoff)\u001b[39m\n\u001b[32m     28\u001b[39m similarity_heap: List[Tuple[\u001b[38;5;28mfloat\u001b[39m, Any]] = []\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings_np):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     similarity = \u001b[43msimilarity_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m similarity_cutoff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m similarity > similarity_cutoff:\n\u001b[32m     32\u001b[39m         heapq.heappush(similarity_heap, (similarity, embedding_ids[i]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_learn/lib/python3.12/site-packages/llama_index/core/base/embeddings/base.py:58\u001b[39m, in \u001b[36msimilarity\u001b[39m\u001b[34m(embedding1, embedding2, mode)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.dot(embedding1, embedding2)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     product = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     norm = np.linalg.norm(embedding1) * np.linalg.norm(embedding2)\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m product / norm\n",
      "\u001b[31mValueError\u001b[39m: shapes (1536,) and (1024,) not aligned: 1536 (dim 0) != 1024 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(\"æ­£åœ¨åˆ›å»ºæé—®å¼•æ“...\")\n",
    "query_engine = index.as_query_engine(\n",
    "    # è®¾ç½®ä¸ºæµå¼è¾“å‡º\n",
    "    streaming=True,\n",
    "    # æ­¤å¤„ä½¿ç”¨qwen-plus-0919æ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘æä¾›çš„å…¶å®ƒqwençš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
    "    llm=OpenAILike(\n",
    "        model=\"qwen-plus\",\n",
    "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        is_chat_model=True\n",
    "        ))\n",
    "print(\"æ­£åœ¨ç”Ÿæˆå›å¤...\")\n",
    "streaming_response = query_engine.query('å†…éƒ¨æ§åˆ¶è¯„ä»·ç»“è®ºï¼Ÿ')\n",
    "print(\"å›ç­”æ˜¯ï¼š\")\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ å¯ä»¥å°†ä¸Šè¿°ä»£ç è¿›è¡Œå°è£…ï¼Œä»¥ä¾¿åœ¨åç»­æŒç»­è¿­ä»£æ—¶å¿«é€Ÿä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chatbot import rag\n",
    "\n",
    "# å¼•æ–‡åœ¨å‰é¢çš„æ­¥éª¤ä¸­å·²ç»å»ºç«‹äº†ç´¢å¼•ï¼Œå› æ­¤è¿™é‡Œå¯ä»¥ç›´æ¥åŠ è½½ç´¢å¼•ã€‚å¦‚æœéœ€è¦é‡å»ºç´¢å¼•ï¼Œå¯ä»¥å¢åŠ ä¸€è¡Œä»£ç ï¼šrag.indexing()\n",
    "index = rag.load_index(persist_path='./knowledge_base/test')\n",
    "query_engine = rag.create_query_engine(index=index)\n",
    "\n",
    "rag.ask('è§£å†³æ–¹æ¡ˆé‡‡ç”¨åˆ†å±‚æ¶æ„ï¼Ÿ', query_engine=query_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 å¤šè½®å¯¹è¯\n",
    "RAGçš„å¤šè½®å¯¹è¯ä¸ç›´æ¥å‘å¤§æ¨¡å‹å‘èµ·å¤šè½®å¯¹è¯æœºåˆ¶ç•¥æœ‰ä¸åŒã€‚ä½ å·²ç»ä»2.1çš„æ•™ç¨‹ä¸­äº†è§£åˆ°å¤šè½®å¯¹è¯å¯ä»¥è®©å¤§æ¨¡å‹å‚è€ƒå†å²å¯¹è¯ä¿¡æ¯ï¼Œå®ç°æ–¹æ³•ä¸ºå°†å†å²å¯¹è¯ä¿¡æ¯æ·»åŠ åˆ°messagesåˆ—è¡¨ä¸­ã€‚\n",
    "\n",
    "åœ¨RAGåº”ç”¨ä¸­çš„æ£€ç´¢é˜¶æ®µï¼Œé€šå¸¸ä¼šå»æ¯”è¾ƒç”¨æˆ·è¾“å…¥ä¸æ–‡æœ¬æ®µçš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œä½†ç›´æ¥å°†ç”¨æˆ·è¾“å…¥ä¸æ–‡æœ¬æ®µè¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒï¼Œå¯èƒ½ä¼šä¸¢å¤±å†å²å¯¹è¯ä¿¡æ¯ï¼Œé€ æˆæ£€ç´¢ç»“æœä¸å‡†ç¡®ã€‚\n",
    "\n",
    "å‡è®¾ç”¨æˆ·åœ¨ç¬¬ä¸€è½®å¯¹è¯æé—®â€œå¼ ä¸‰å·¥ä½åœ¨å“ªé‡Œï¼Ÿâ€åï¼Œåœ¨ç¬¬äºŒè½®å¯¹è¯æé—®â€œä»–çš„ä¸»ç®¡æ˜¯è°ï¼Ÿâ€ï¼Œå¦‚æœç›´æ¥å°†ç¬¬äºŒè½®å¯¹è¯ä¸­çš„æé—®ä¸æ–‡æœ¬æ®µè¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒï¼Œæ£€ç´¢ç³»ç»Ÿå¹¶ä¸çŸ¥é“â€œä»–â€æŒ‡ä»£çš„æ˜¯è°ï¼Œå› æ­¤å¤§æ¦‚ç‡ä¼šæ£€ç´¢å‡ºé”™è¯¯çš„æ–‡æœ¬æ®µã€‚\n",
    "\n",
    "å¦‚æœå°†å®Œæ•´å†å²å¯¹è¯ä¸é—®é¢˜éƒ½è¾“å…¥åˆ°æ£€ç´¢ç³»ç»Ÿï¼Œç”±äºå­—æ•°è¾ƒå¤šï¼Œæ£€ç´¢ç³»ç»Ÿå¯èƒ½æ— æ³•å¤„ç†ï¼ˆembeddingæ¨¡å‹åœ¨é•¿æ–‡æœ¬ä¸Šæ•ˆæœå·®äºçŸ­æ–‡æœ¬ï¼‰ã€‚ä¸šç•Œå¸¸ç”¨çš„è§£å†³æ–¹æ³•æ˜¯ï¼š\n",
    "\n",
    "1. é€šè¿‡å¤§æ¨¡å‹ï¼ŒåŸºäºå†å²å¯¹è¯ä¿¡æ¯ï¼Œå°†ç”¨æˆ·çš„é—®é¢˜æ”¹å†™ä¸ºä¸€ä¸ªæ–°çš„queryï¼Œæ–°çš„queryå°†åŒ…å«å†å²å¯¹è¯çš„å…³é”®ä¿¡æ¯ã€‚\n",
    "2. ä½¿ç”¨æ–°çš„queryï¼ŒæŒ‰ç…§åŸå…ˆæµç¨‹è¿›è¡Œæ£€ç´¢ä¸ç”Ÿæˆçš„è¿‡ç¨‹ã€‚\n",
    "\n",
    "LlamaIndexæä¾›äº†ä¾¿æ·çš„å·¥å…·ï¼Œå¯ä»¥å¿«é€Ÿå®ç°RAGåº”ç”¨çš„å¤šè½®å¯¹è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: åœ¨è®¨è®ºä¸šåŠ¡å˜æ›´æ—¶ï¼Œæåˆ°çš„â€œå˜æ›´æœ€å¤§è·¯ç”±â€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿå¦å¤–ï¼Œå˜æ›´äººå·¥æœåŠ¡çº§åˆ«å…·ä½“æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "åœ¨å½“å‰æä¾›çš„ä¿¡æ¯ä¸­ï¼Œå¹¶æ²¡æœ‰ç›´æ¥æåŠâ€œå˜æ›´æœ€å¤§è·¯ç”±â€æˆ–â€œå˜æ›´äººå·¥æœåŠ¡çº§åˆ«â€çš„å…·ä½“å®šä¹‰ã€‚ä¸è¿‡ï¼Œæ ¹æ®é€šå¸¸çš„ç†è§£ï¼š\n",
      "\n",
      "â€œå˜æ›´æœ€å¤§è·¯ç”±â€å¯èƒ½æ˜¯æŒ‡åœ¨ç½‘ç»œé…ç½®æˆ–è·¯ç”±é€‰æ‹©ä¸­ï¼Œå¯¹å¯ä»¥å¤„ç†çš„æœ€å¤§è·¯å¾„æˆ–è¿æ¥æ•°è¿›è¡Œè°ƒæ•´ã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°ç½‘ç»œæ¶æ„çš„ä¼˜åŒ–ï¼Œä»¥é€‚åº”ä¸šåŠ¡éœ€æ±‚çš„å˜åŒ–ï¼Œæ¯”å¦‚å¢åŠ å¸¦å®½ã€æé«˜æ•°æ®ä¼ è¾“æ•ˆç‡ç­‰ã€‚\n",
      "\n",
      "â€œå˜æ›´äººå·¥æœåŠ¡çº§åˆ«â€åˆ™å¯èƒ½æ˜¯æŒ‡è°ƒæ•´æä¾›ç»™å®¢æˆ·çš„äººå·¥æœåŠ¡æ ‡å‡†æˆ–è´¨é‡ã€‚è¿™åŒ…æ‹¬ä½†ä¸é™äºæ”¹å˜å“åº”æ—¶é—´ã€æœåŠ¡å¯ç”¨æ€§ã€æœåŠ¡è´¨é‡ç­‰æŒ‡æ ‡ï¼Œä»¥æ›´å¥½åœ°æ»¡è¶³å®¢æˆ·éœ€æ±‚æˆ–ä¼˜åŒ–æˆæœ¬ç»“æ„ã€‚ä¾‹å¦‚ï¼Œå¯èƒ½å°†æŸäº›æœåŠ¡ä»24å°æ—¶æ”¯æŒæ”¹ä¸ºå·¥ä½œæ—¶é—´æ”¯æŒï¼Œæˆ–è€…æé«˜ç‰¹å®šæ—¶é—´æ®µå†…çš„å“åº”é€Ÿåº¦ã€‚\n",
      "\n",
      "ç„¶è€Œï¼Œè¿™äº›è§£é‡ŠåŸºäºä¸€èˆ¬æƒ…å†µä¸‹çš„ç†è§£ï¼Œåœ¨å…·ä½“åœºæ™¯ä¸­å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ è‹¥è¦è·å¾—æ›´å‡†ç¡®çš„è§£é‡Šï¼Œå»ºè®®æŸ¥é˜…ç›¸å…³æ–‡æ¡£æˆ–å’¨è¯¢ä¸šåŠ¡å˜æ›´çš„å…·ä½“è´Ÿè´£äººã€‚"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "ç»™å®šä¸€æ®µå¯¹è¯ï¼ˆåœ¨äººç±»ä¸åŠ©æ‰‹ä¹‹é—´ï¼‰ä»¥åŠæ¥è‡ªäººç±»çš„åç»­ä¿¡æ¯ï¼Œ\n",
    "è¯·å°†è¯¥ä¿¡æ¯æ”¹å†™ä¸ºä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ï¼Œå¹¶åœ¨å…¶ä¸­åŒ…å«å¯¹è¯ä¸­çš„æ‰€æœ‰ç›¸å…³ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "<èŠå¤©è®°å½•>\n",
    "{chat_history}\n",
    "\n",
    "<åç»­ä¿¡æ¯>\n",
    "{question}\n",
    "\n",
    "<ç‹¬ç«‹çš„é—®é¢˜>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# å†å²å¯¹è¯ä¿¡æ¯\n",
    "custom_chat_history = [\n",
    "    ChatMessage(role=MessageRole.USER,content=\"ä¸šåŠ¡å˜æ›´æ˜¯æŒ‡ï¼Ÿ\"),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=\"å˜æ›´æœ€å¤§è·¯ç”±ã€‚\"),\n",
    "]\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    # è®¾ç½®ä¸ºæµå¼è¾“å‡º\n",
    "    streaming=True,\n",
    "    # æ­¤å¤„ä½¿ç”¨qwen-plus-0919æ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨é˜¿é‡Œäº‘æä¾›çš„å…¶å®ƒqwençš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models#9f8890ce29g5u\n",
    "    llm=OpenAILike(\n",
    "        model=\"qwen-plus-0919\",\n",
    "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        is_chat_model=True\n",
    "        ))\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    condense_question_prompt=custom_prompt,\n",
    "    chat_history=custom_chat_history,\n",
    "    llm=OpenAILike(\n",
    "        model=\"qwen-plus-0919\",\n",
    "        api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        is_chat_model=True\n",
    "        ),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "streaming_response = chat_engine.stream_chat(\"å˜æ›´äººå·¥æœåŠ¡çº§åˆ«ï¼Ÿ\")\n",
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è™½ç„¶æœ€åä¸€ä¸ªé—®é¢˜æ²¡æœ‰æåˆ°â€œå†…å®¹å¼€å‘å·¥ç¨‹å¸ˆâ€ï¼Œä½†å¤§æ¨¡å‹è¿˜æ˜¯æ ¹æ®å†å²å¯¹è¯ä¿¡æ¯ï¼Œå°†é—®é¢˜æ”¹å†™ä¸ºâ€œå†…å®¹å¼€å‘å·¥ç¨‹å¸ˆçš„æ ¸å¿ƒèŒè´£æ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼Œå¹¶ç»™å‡ºäº†æ­£ç¡®çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“3.æœ¬èŠ‚å°ç»“\n",
    "åœ¨æœ¬èŠ‚è¯¾ç¨‹ä¸­ï¼Œä½ å­¦ä¹ äº†ä»¥ä¸‹å†…å®¹ï¼š\n",
    "1. **RAGçš„å·¥ä½œåŸç†**<br>\n",
    "ä¸€ä¸ªå®Œæ•´çš„RAGåº”ç”¨é€šå¸¸åŒ…å«å»ºç«‹ç´¢å¼•ä¸æ£€ç´¢ç”Ÿæˆä¸¤ä¸ªé˜¶æ®µï¼Œå»ºç«‹ç´¢å¼•åŒ…æ‹¬æ–‡æ¡£è§£æã€æ–‡æœ¬åˆ†æ®µã€æ–‡æœ¬å‘é‡åŒ–ã€å­˜å‚¨ç´¢å¼•å››ä¸ªæ­¥éª¤ï¼Œæ£€ç´¢ç”Ÿæˆé˜¶æ®µåŒ…æ‹¬æ£€ç´¢ä¸ç”Ÿæˆä¸¤ä¸ªæ­¥éª¤ã€‚å¯¹RAGçš„å·¥ä½œåŸç†æœ‰äº†äº†è§£åï¼Œä½ å°±å¯ä»¥æ›´æœ‰é’ˆå¯¹æ€§åœ°å¯¹ç­”ç–‘æœºå™¨äººä¼˜åŒ–ä¸è¿­ä»£ã€‚\n",
    "2. **åˆ›å»ºRAGåº”ç”¨**<br>\n",
    "é€šè¿‡LlamaIndexæä¾›çš„é«˜åº¦é›†æˆåŒ–å·¥å…·ï¼Œä½ åˆ›å»ºäº†ä¸€ä¸ªRAGåº”ç”¨ï¼Œå¹¶æŒæ¡äº†ä¿å­˜ä¸åŠ è½½ç´¢å¼•çš„æ–¹æ³•ï¼ŒåŒæ—¶ä½ ä¹Ÿå­¦ä¹ äº†å¦‚ä½•åœ¨RAGåº”ç”¨ä¸­å®ç°å¤šè½®å¯¹è¯çš„æ–¹æ³•ã€‚\n",
    "\n",
    "è™½ç„¶ç­”ç–‘æœºå™¨äººå·²ç»å¯ä»¥å¾ˆå¥½åœ°å›ç­”â€œæˆ‘ä»¬å…¬å¸é¡¹ç›®ç®¡ç†åº”è¯¥ç”¨ä»€ä¹ˆå·¥å…·â€ç­‰é—®é¢˜ï¼Œä½†å½“å‰çš„åŠŸèƒ½è¿˜æ˜¯æ¯”è¾ƒç®€å•ï¼Œåœ¨åç»­çš„æ•™ç¨‹ä¸­æˆ‘ä»¬ä¼šå‘ä½ ä»‹ç»æ‹“å±•ç­”ç–‘æœºå™¨äººèƒ½åŠ›è¾¹ç•Œçš„æ–¹æ³•ã€‚ä¸‹ä¸€å°èŠ‚æˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•é€šè¿‡ä¼˜åŒ–æç¤ºè¯æ¥æ”¹å–„ç­”ç–‘æœºå™¨äººçš„å›ç­”è´¨é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‹“å±•é˜…è¯»\n",
    "\n",
    "#### æ–‡æœ¬å‘é‡åŒ–\n",
    "è®¡ç®—æœºå¹¶ä¸èƒ½ç›´æ¥ç†è§£â€œæˆ‘å–œæ¬¢åƒè‹¹æœâ€ä¸â€œæˆ‘çˆ±åƒè‹¹æœâ€è¿™ä¸¤å¥è¯åˆ°åº•æœ‰å¤šç›¸ä¼¼ï¼Œä½†å®ƒèƒ½ç†è§£ä¸¤ä¸ªç›¸åŒç»´åº¦çš„å‘é‡çš„ç›¸ä¼¼åº¦ï¼ˆé€šå¸¸ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡ï¼‰ã€‚æ–‡æœ¬å‘é‡åŒ–é€šè¿‡embeddingæ¨¡å‹ï¼Œå°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºè®¡ç®—æœºèƒ½å¤Ÿç†è§£çš„æ•°å­—å½¢å¼ã€‚\n",
    "\n",
    "embeddingæ¨¡å‹çš„è®­ç»ƒé€šå¸¸ä¼šåŒ…å«**å¯¹æ¯”å­¦ä¹ **çš„ç¯èŠ‚ï¼Œè¾“å…¥æ•°æ®æ˜¯è®¸å¤šå·²æ ‡è®°ä¸ºæ˜¯å¦ç›¸å…³çš„æ–‡æœ¬å¯¹(s1,s2)ï¼Œæ¨¡å‹çš„è®­ç»ƒç›®æ ‡æ˜¯å°½å¯èƒ½è®©ç›¸å…³çš„æ–‡æœ¬å¯¹ç”Ÿæˆçš„å‘é‡ç›¸ä¼¼åº¦å˜é«˜ï¼Œä¸ç›¸å…³çš„æ–‡æœ¬å¯¹ç”Ÿæˆçš„å‘é‡ç›¸ä¼¼åº¦å˜ä½ã€‚\n",
    "\n",
    "åœ¨**å»ºç«‹ç´¢å¼•**é˜¶æ®µï¼Œå‡è®¾å·²ç»é€šè¿‡æ–‡æœ¬åˆ†æ®µè·å¾—äº†nä¸ªchunkï¼š[c1,c2,c3,...,cn]ï¼Œé‚£ä¹ˆembeddingæ¨¡å‹ä¼šå°†è¿™nä¸ªchunkåˆ†åˆ«è½¬åŒ–ä¸ºå‘é‡ï¼š[v1,v2,v3,...,vn]ï¼Œå¹¶å­˜å‚¨ä¸ºå‘é‡æ•°æ®åº“ã€‚\n",
    "\n",
    "åœ¨**æ£€ç´¢**é˜¶æ®µï¼Œå‡è®¾ç”¨æˆ·çš„é—®é¢˜ä¸ºqï¼Œé‚£ä¹ˆembeddingæ¨¡å‹ä¼šå°†é—®é¢˜qè½¬åŒ–ä¸ºå‘é‡vqï¼Œå¹¶åœ¨å‘é‡æ•°æ®åº“ä¸­æ‰¾å‡ºä¸vqæœ€ç›¸ä¼¼çš„nä¸ªå‘é‡ï¼ˆè¿™ä¸ªå€¼ä½ å¯ä»¥è‡ªå·±è®¾å®šï¼‰ï¼Œé€šè¿‡å‘é‡ä¸æ–‡æœ¬æ®µçš„ç´¢å¼•å…³ç³»å¾—åˆ°æ–‡æœ¬æ®µï¼Œä½œä¸ºæ£€ç´¢ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯¾åå°æµ‹éªŒ\n",
    "ã€å•é€‰é¢˜ã€‘ åœ¨RAGåº”ç”¨ä¸­è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œåº”è¯¥å¦‚ä½•è¿›è¡Œæ£€ç´¢ï¼Ÿ\n",
    "\n",
    "A. åœ¨æ£€ç´¢é˜¶æ®µè¾“å…¥å®Œæ•´çš„å†å²å¯¹è¯ä¿¡æ¯<br>\n",
    "B. ç»“åˆå†å²å¯¹è¯ä¿¡æ¯å¯¹è¾“å…¥é—®é¢˜æ”¹å†™åè¿›å…¥æ£€ç´¢é˜¶æ®µ<br>\n",
    "C. åœ¨æ£€ç´¢é˜¶æ®µè¾“å…¥æœ€æ–°çš„è¾“å…¥é—®é¢˜<br>\n",
    "D. å°†ä¸Šä¸€è½®å¬å›çš„æ–‡æœ¬æ®µè¿ç§»è¿‡æ¥<br>\n",
    "å‚è€ƒç­”æ¡ˆï¼šB<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ…è¯„ä»·åé¦ˆ\n",
    "æ¬¢è¿ä½ å‚ä¸[é˜¿é‡Œäº‘å¤§æ¨¡å‹ACPè¯¾ç¨‹é—®å·](https://survey.aliyun.com/apps/zhiliao/Mo5O9vuie) åé¦ˆå­¦ä¹ ä½“éªŒå’Œè¯¾ç¨‹è¯„ä»·ã€‚\n",
    "ä½ çš„æ‰¹è¯„å’Œé¼“åŠ±éƒ½æ˜¯æˆ‘ä»¬å‰è¿›çš„åŠ¨åŠ›ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_learn",
   "language": "python",
   "name": "llm_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

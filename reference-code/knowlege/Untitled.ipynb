{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa54ba3-58f9-44fb-84b0-e817408dd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''欢迎来到大模型开发框架实战课\n",
    "\n",
    "作者 杨勇'''\n",
    "\n",
    "# 1.这里加载 key\n",
    "from config.load_key import load_key\n",
    "import os\n",
    "load_key()\n",
    "from fontTools.ttLib.tables.ttProgram import instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0ae5e3-5eff-46ce-8273-ae8ec1deaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.加载向量库和索引\n",
    "persist_path = './knowledge_base/test'\n",
    "if not os.path.exists(persist_path):\n",
    "    raise FileNotFoundError(f\"知识库路径 {persist_path} 不存在，请检查配置\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ade355-16c7-4ec6-87c4-56aa51b0cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /root/miniconda3/envs/study3.12.4/lib/python3.12/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ToolCallBlock' from 'llama_index.core.base.llms.types' (/root/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/core/base/llms/types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchatbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rag\n\u001b[32m      2\u001b[39m index = rag.load_index(persist_path=persist_path)\n\u001b[32m      3\u001b[39m query_engine = rag.create_query_engine(index=index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/study/knowlege/chatbot/rag.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      7\u001b[39m logging.basicConfig(level=logging.ERROR)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai_like\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mindexing\u001b[39m(document_path=\u001b[33m\"\u001b[39m\u001b[33m./docs\u001b[39m\u001b[33m\"\u001b[39m, persist_path=\u001b[33m\"\u001b[39m\u001b[33mknowledge_base/test\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/llms/openai_like/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai_like\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[32m      3\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mOpenAILike\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/llms/openai_like/base.py:20\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CONTEXT_WINDOW\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     async_stream_completion_response_to_chat_response,\n\u001b[32m     17\u001b[39m     completion_response_to_chat_response,\n\u001b[32m     18\u001b[39m     stream_completion_response_to_chat_response,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI, Tokenizer\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mOpenAILike\u001b[39;00m(OpenAI):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/llms/openai/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, OpenAI, SyncOpenAI, Tokenizer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIResponses\n\u001b[32m      4\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mOpenAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mOpenAIResponses\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTokenizer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSyncOpenAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAsyncOpenAI\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/llms/openai/base.py:36\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstrumentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minstrument\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     achat_to_completion_decorator,\n\u001b[32m     28\u001b[39m     acompletion_to_chat_decorator,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     stream_completion_to_chat_decorator,\n\u001b[32m     35\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     ChatMessage,\n\u001b[32m     38\u001b[39m     ChatResponse,\n\u001b[32m     39\u001b[39m     ChatResponseAsyncGen,\n\u001b[32m     40\u001b[39m     ChatResponseGen,\n\u001b[32m     41\u001b[39m     CompletionResponse,\n\u001b[32m     42\u001b[39m     CompletionResponseAsyncGen,\n\u001b[32m     43\u001b[39m     CompletionResponseGen,\n\u001b[32m     44\u001b[39m     LLMMetadata,\n\u001b[32m     45\u001b[39m     MessageRole,\n\u001b[32m     46\u001b[39m     ToolCallBlock,\n\u001b[32m     47\u001b[39m     TextBlock,\n\u001b[32m     48\u001b[39m )\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbridge\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     50\u001b[39m     Field,\n\u001b[32m     51\u001b[39m     PrivateAttr,\n\u001b[32m     52\u001b[39m )\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ToolCallBlock' from 'llama_index.core.base.llms.types' (/root/miniconda3/envs/study3.12.4/lib/python3.12/site-packages/llama_index/core/base/llms/types.py)"
     ]
    }
   ],
   "source": [
    "from chatbot import rag\n",
    "index = rag.load_index(persist_path=persist_path)\n",
    "query_engine = rag.create_query_engine(index=index)\n",
    "\n",
    "# 添加调试日志\n",
    "print(f\"索引加载成功，路径：{persist_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48919d73-49e5-46c8-b3cc-b960dbdb8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 问答系统的UI实现采用 flask框架\n",
    "from flask import Flask, request, jsonify, Response, render_template\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)  # Flask APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bb893-662d-4326-87cb-889dfe0947cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study3.12.4",
   "language": "python",
   "name": "study3.12.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
